/**
 * Deep Learning Filter Module
 * Uses Transformers.js for zero-shot classification
 * Designed for modern hardware with 2GB+ RAM
 */

// Dynamic import for ESM module
let pipeline = null;
let env = null;

// Model state
let classifier = null;
let isLoading = false;
let loadProgress = 0;


// Greek stopwords (common words to ignore when extracting suspicious words)
const GREEK_STOPWORDS = new Set([
    'ÎºÎ±Î¹', 'Ï„Î¿', 'Ï„Î±', 'Î·', 'Î¿Î¹', 'Î¿', 'Ï„Î¿Ï…', 'Ï„Î·Ï‚', 'Ï„Ï‰Î½', 'Ï„Î¿Î½', 'Ï„Î·Î½',
    'ÏƒÏ„Î¿', 'ÏƒÏ„Î·', 'ÏƒÏ„Î±', 'ÏƒÏ„Î¿Î½', 'ÏƒÏ„Î·Î½', 'Î¼Îµ', 'Î³Î¹Î±', 'Î½Î±', 'Î¸Î±', 'ÎµÎ¯Î½Î±Î¹',
    'Î­Ï‡ÎµÎ¹', 'Î±Ï€ÏŒ', 'Ï€Î¿Ï…', 'Î±Ï…Ï„ÏŒ', 'Î±Ï…Ï„Î¬', 'Î±Ï…Ï„ÏŒÏ‚', 'Î±Ï…Ï„Î®', 'ÎµÎ³Ï', 'ÎµÏƒÏ',
    'ÎµÎ¼ÎµÎ¯Ï‚', 'ÎµÏƒÎµÎ¯Ï‚', 'Î±Ï…Ï„Î¿Î¯', 'Î±Ï…Ï„Î­Ï‚', 'Î¼Î¿Ï…', 'ÏƒÎ¿Ï…', 'Ï„Î¿Ï…', 'Ï„Î·Ï‚', 'Î¼Î±Ï‚',
    'ÏƒÎ±Ï‚', 'Ï„Î¿Ï…Ï‚', 'Î´ÎµÎ½', 'Î¼Î·Î½', 'Ï€Ï‰Ï‚', 'Ï€ÏÏ‚', 'Ï„Î¹', 'Ï€Î¿Î¹Î¿Ï‚', 'Ï€Î¿Î¹Î±', 'Ï€Î¿Î¹Î¿',
    'Ï€ÏŒÏ„Îµ', 'Ï€Î¿Ï', 'Î³Î¹Î±Ï„Î¯', 'Î±Î½', 'ÏŒÏ„Î±Î½', 'ÎµÎ½Ï', 'Î±Î»Î»Î¬', 'ÏŒÎ¼Ï‰Ï‚', 'Î»Î¿Î¹Ï€ÏŒÎ½',
    'Î®Î´Î·', 'Î±ÎºÏŒÎ¼Î±', 'Ï€Î¿Î»Ï', 'Î»Î¯Î³Î¿', 'Ï€Î¬ÏÎ±', 'Ï€Î¹Î¿', 'Ï€ÏÎ­Ï€ÎµÎ¹', 'Î¼Ï€Î¿ÏÏ', 'Î¼Ï€Î¿ÏÎµÎ¯Ï‚',
    'ÎºÎ±Î»Î¬', 'Ï‰ÏÎ±Î¯Î±', 'ÎµÎ½Ï„Î¬Î¾ÎµÎ¹', 'Î½Î±Î¹', 'ÏŒÏ‡Î¹', 'Î¯ÏƒÏ‰Ï‚', 'Î¼Î¬Î»Î»Î¿Î½', 'ÏƒÎ¯Î³Î¿Ï…ÏÎ±'
]);

// English stopwords
const ENGLISH_STOPWORDS = new Set([
    'the', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'be',
    'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
    'could', 'should', 'may', 'might', 'must', 'shall', 'can', 'need', 'dare',
    'ought', 'used', 'to', 'of', 'in', 'for', 'on', 'with', 'at', 'by', 'from',
    'as', 'into', 'through', 'during', 'before', 'after', 'above', 'below',
    'between', 'under', 'again', 'further', 'then', 'once', 'here', 'there',
    'when', 'where', 'why', 'how', 'all', 'each', 'few', 'more', 'most', 'other',
    'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than',
    'too', 'very', 'just', 'also', 'now', 'i', 'you', 'he', 'she', 'it', 'we',
    'they', 'me', 'him', 'her', 'us', 'them', 'my', 'your', 'his', 'its', 'our',
    'their', 'this', 'that', 'these', 'those', 'what', 'which', 'who', 'whom'
]);

// Combined stopwords
const ALL_STOPWORDS = new Set([...GREEK_STOPWORDS, ...ENGLISH_STOPWORDS]);

/**
 * Load the zero-shot classification model
 * @param {Function} progressCallback - Called with progress updates (0-100)
 * @returns {Promise<boolean>} - True if model loaded successfully
 */
async function loadModel(progressCallback) {
    if (classifier) {
        return true; // Already loaded
    }

    if (isLoading) {
        return false; // Already loading
    }

    isLoading = true;
    loadProgress = 0;

    try {
        console.log('ğŸ§  Loading Deep Learning model...');

        // Dynamic import for ESM module
        if (!pipeline) {
            console.log('ğŸ§  Importing Transformers.js...');
            const transformers = await import('@xenova/transformers');
            pipeline = transformers.pipeline;
            env = transformers.env;

            // Configure Transformers.js
            env.useBrowserCache = false;
            env.allowLocalModels = true;
        }

        classifier = await pipeline(
            'text-classification',
            'Xenova/toxic-bert',
            {
                quantized: true,
                progress_callback: (progress) => {
                    if (progress.status === 'progress' && progress.total) {
                        loadProgress = Math.round((progress.loaded / progress.total) * 100);
                        if (progressCallback) {
                            progressCallback({
                                status: 'downloading',
                                progress: loadProgress,
                                file: progress.file || 'model'
                            });
                        }
                        console.log(`ğŸ§  Model download: ${loadProgress}%`);
                    } else if (progress.status === 'done') {
                        if (progressCallback) {
                            progressCallback({ status: 'ready', progress: 100 });
                        }
                    }
                }
            }
        );

        console.log('âœ… Deep Learning model loaded successfully!');
        isLoading = false;
        return true;
    } catch (error) {
        console.error('âŒ Failed to load Deep Learning model:', error);
        isLoading = false;
        classifier = null;
        return false;
    }
}

/**
 * Check if the model is ready
 * @returns {boolean}
 */
function isModelReady() {
    return classifier !== null;
}

/**
 * Check if the model is currently loading
 * @returns {boolean}
 */
function isModelLoading() {
    return isLoading;
}

/**
 * Get current load progress
 * @returns {number} 0-100
 */
function getLoadProgress() {
    return loadProgress;
}

/**
 * Classify a message using toxic-bert text classification
 * @param {string} message - The message to classify
 * @returns {Promise<{isProfane: boolean, confidence: number, category: string, tier: string}>}
 */
async function classifyMessage(message) {
    if (!classifier) {
        return { isProfane: false, confidence: 0, category: 'unknown', tier: 'safe' };
    }

    try {
        // toxic-bert returns: { label: 'toxic' or 'non-toxic', score: 0.0-1.0 }
        const result = await classifier(message);

        // Handle array or single result
        const output = Array.isArray(result) ? result[0] : result;
        const label = output.label?.toLowerCase() || '';
        const score = output.score || 0;

        // Determine if profane (toxic-bert labels: toxic, severe_toxic, obscene, threat, insult, identity_hate)
        const toxicLabels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'];
        const isProfane = toxicLabels.some(l => label.includes(l)) || label === 'label_1';

        // Determine tier based on confidence
        let tier = 'safe';
        if (isProfane && score > 0.90) {
            tier = 'high';
        } else if (isProfane && score > 0.60) {
            tier = 'medium';
        }

        console.log(`ğŸ§  Classification: "${message.substring(0, 30)}..." â†’ ${label} (${Math.round(score * 100)}%)`);

        return {
            isProfane,
            confidence: Math.round(score * 100),
            category: label,
            tier
        };
    } catch (error) {
        console.error('âŒ Classification error:', error);
        return { isProfane: false, confidence: 0, category: 'error', tier: 'safe' };
    }
}

/**
 * Extract suspicious words from a toxic message
 * Filters out common stopwords to find likely bad words
 * @param {string} message - The toxic message
 * @returns {string[]} - Array of suspicious words
 */
function extractSuspiciousWords(message) {
    // Normalize and split
    const words = message
        .toLowerCase()
        .replace(/[^\p{L}\p{N}\s]/gu, ' ') // Keep letters and numbers, remove punctuation
        .split(/\s+/)
        .filter(word => word.length > 2); // Ignore very short words

    // Filter out stopwords
    const suspiciousWords = words.filter(word => !ALL_STOPWORDS.has(word));

    // Return unique words
    return [...new Set(suspiciousWords)];
}

/**
 * Unload the model to free memory
 */
function unloadModel() {
    classifier = null;
    loadProgress = 0;
    console.log('ğŸ§  Deep Learning model unloaded');
}

module.exports = {
    loadModel,
    isModelReady,
    isModelLoading,
    getLoadProgress,
    classifyMessage,
    extractSuspiciousWords,
    unloadModel
};
